# Czateria updated
*Wersja poprawiona ze względu na sprecyzowanie wymagań na zajęciach 1.06 + od tamtej pory poznałem markdowna* : )

## Zadanie 1:

**Moim zdaniem inteligencji od człowieka wymagają:**

  - streszczanie tekstu
  - klasyfikacja tekstu do kategorii tematycznych
  - komponowanie muzyki

*Ponieważ wymagają inwencji twórczej i charakteru co nadaje im ludzkości*

## Zadanie 2:

**Moim zdaniem w zakresie sztucznej inteligencji mieszczą się:**

  - tłumaczenie tekstu
  - odpowiadanie na proste pytania zadawane w języku naturalnym
  - rozwiązywanie układów równań
  - układanie rozkładu jazdy
  - rozwiązywanie układów równań liniowych
  - symboliczne obliczanie pochodnych
  - symboliczne całkowanie
  - kierowanie samochodem
  
*Ponieważ są to czynności, które wymagają wyłącznie nauczenia maszyny pewnych zwrotów do rozpoznawania i reagowania lub są rozwiązywalne za pomocą różnych algorytmów matematycznych.*
  
## Zad 3:

**Skutecznie implementowane:**

  - rozmowa towarzyska
  - odpowiadanie na pytania klientów w internetowej infolinii

*Ponieważ nie wymagają bardzo szybkiego działania oraz wysokiego zrozumienia przekazywanej wiadomości*
  
**Nieskutecznie implementowane:**

  - dyskusja polityczna - *do polityki potrzeba ludzkiej wrażliwości i przekonań oraz musiałaby dużo kłamać i się nie przyznawać...*
  - dyskusja naukowa - *dla SI nie byłoby dyskusji naukowej ponieważ posiada wszelką zaimplementowaną wiedzę i dobrze nauczona zawsze posiadałaby najpoprawniejsze opinie*
  - odpowiadanie na pytania klientów w telefonicznej infolinii - *proces rozpoznawania głosu jest za wolny i zbyt wadliwy + najpewniej bardzo często słowa byłyby źle rozpoznane ze względu na jakość połączenia*
  
## Zad 4:
*Wybrane boty:*
https://www.ikea.com/pl/pl/customer-service/contact-us/ - chatbot Billie
https://www.cleverbot.com/ - Cleverbot

### 1.
  **Billie** - bot stworzony jedynie jako asystent. Na jakiekolwiek personalne pytanie sugerował połączenie z człowiekiem lub zmieniał temat rozmowy na obsługę klienta

  **Cleverbot** - bot udający człowieka - podczas krótkiej rozmowy, bot z przekonaniem trzykrotnie starał się mi wmówić, że jest człowiekiem i nie akceptował zupełnie innej możliwości

*Wniosek - różnice między botem udającym człowieka (przygotowywanym na test Turinga) a botem „asystentem, służącym” są bardzo łatwe do rozpoznania, np:*
  - bot udający człowieka nie będzie chciał przyznać, że nie jest człowiekiem, zaś asystent w zasadzie sam od razu o tym powie
  - z botem udającym człowieka da się porozmawiać na różne tematy, a nawet usłyszeć jego opinię. Asystent będzie zazwyczaj ucinał rozmowę i informował o swoim przeznaczeniu
  - bot udający człowieka okazjonalnie sam zapoczątkuje rozmowę na dany temat, a asystent będzie czekał na polecenie od człowieka
### 2.

#### a)

  **Billie** - bot opowiedział dosyć suchy żart, który brzmiał jak coś przygotowanego dokładnie na tę prośbę przez zespół promocyjny Ikea - lokowanie nazwy sklepu, a także typowych cech:
  *'Facet idzie na rozmowę kwalifikacyjną do IKEA… Kierownik mówi "Witamy! Wejdź i stwórz swoje stanowisko."'*

  **Cleverbot** - po prośbie opowiedział żart językowy w kilku wiadomościach - rodzaju “puk,puk … kto tam?” wymagający mojej aktywności:
  *'Knock knock. | Who's there? | Mr. Lettuce | A Lettuce who? | Lettuce in! It's freezing out here!'*
  Co również ciekawe, to że pierwotnie odmówił mi na prośbę i poprosił mnie o opowiedzenie swojego żartu najpierw.

#### b)

  **Billie** - bot kompletnie sobie nie poradził, a na pytanie o cytat Shakespeara zaczął mi opowiadać żart o taborecie.

  **Cleverbot** - bot nie reagował na prośby o cytaty znanych osób i zmieniał temat. Kiedy poprosiłem o mój cytat, powiedział coś czego wcześniej nie powiedziałem, a kiedy zaprzeczyłem powiedział że jego życie jest kłamstwem, ponieważ ja jestem robotem.

#### c)
  **Billie** - bot w zasadzie nie zapamiętywał kontekstu rozmowy między wiadomościami, także nie było szansy na nawiązanie wypowiedzi do słów kluczowych.

  **Cleverbot** - powiedziałem botowi, że pochodzę z Grecji - po wymianie paru wiadomości spytałem się go skąd pochodzę i nie był w stanie odpowiedzieć - najpierw odpowiedział zupełnie nieadekwatnie do pytania, a za drugim razem odpowiedział "You come from the mind of your programmer".

#### d)
  **Billie** - bot nie radzi sobie z wieloma pytaniami - odpowiada (często błędnymi!) linkami do strony Ikei.

  **Cleverbot** - bot skutecznie odpowiada na różne pytania, ale często zupełnie odmawia odpowiedzi - nie z braku wiedzy, a bardziej z braku chęci.

#### e)
  **Billie** - bot nie pamięta poprzednich wiadomości.

  **Cleverbot** - bot nie pamięta początku konwersacji, ale utrzymuje wątki w zasięgu kilku wiadomości.

#### f)
  **Billie** - bot nie zadaje pytań, poza propozycją dalszej pomocy lub połączeniem z pracownikiem.

  **Cleverbot** - bot często pytał mnie o rzeczy, o które go pytałem wcześniej.

#### g)
  **Billie** - bot kompletnie ignorował każde personalne pytanie, jedynie odsyłając link do artykułów na stronie Ikea, które nie miały żadnego związku z pytaniem.

  **Cleverbot** - bot bardzo często odpowiadał wymijająco i był bardzo skryty - im więcej zadawału mu się pytań, tym mniej chciał na nie odpowiadać.

#### h)
  **Billie** - ciężko mówić o zmianie tematu rozmowy, jeżeli jedna strona zupełnie jej nie podtrzymuje.

  **Cleverbot** - bot często zmieniał temat rozmowy, ale robił to w stosunkowo “ludzki” sposób - kiedy dany temat się wyczerpywał, to zdarzało mu się płynnie przechodzić w pokrewny lub rozpoczynać zupelnie nową dyskusję.

#### i)
  **Billie** - bot zupełnie nie trzymał wątków.

  **Cleverbot** - bot utrzymywał wątki na kilka wiadomości.

### 3.
  **Billie** jest ewidentnie botem do pomocy klientowi Ikei w sprawie zgłaszania usterek i pomocy. Ma bardzo ograniczone możliwości i w większości przypadków nawet zawodzi w zakresie swoich oczekiwanych obowiązków. Z "ludzkich cech" posiada on zdolność do opowiadania bardzo podstawowych sucharów związanych z Ikeą, ale nie da się z nim poprowadzić jakiejkolwiek sensownej rozmowy, a tym bardziej dyskusji.

  **Cleverbot** jest stosunkowo rozbudowanym botem, który nie chce się przyznać do bycia botem. Ma stosunkowo ograniczoną pamięć, ale potrafi podtrzymywać rozmowę, a nawet samemu ją rozpoczynać. Moim zdaniem przeprowadzając z nim (i równie upartym człowiekiem) test Turinga, istnieje pewna szansa na pomylenie go z osobą.

### 4.
  *Na rzecz tego zadania zmieniłem Billiego na bardziej “myślącego bota”: https://www.personalityforge.com/chat/cyber_ty*

  Podchodząc do tego zadania przewidywałem, że rozmowa będzie bardzo nieciekawa i prawdopodobnie się zapętli wokół kilku pytań. Zakładałem że tematy proponowane przez boty będą bardzo proste i skończy się na wzajemnej kłótni.

  Przeprowadziłem rozmowę między botami i była bardzo chaotyczna. Po przywitaniu i paru ogólnych wiadomościach Cyber Ty zaczął bardzo agresywnie wyzywać Cleverbota (bez większego powodu), na co Cleverbot odpowiadał swoimi "łagodniejszymi" wyzwiskami. Ostatecznie kłótnie przerwało niezrozumienie Cleverbota. W dalszej części rozmowy Cyber Ty zaczął zadawać bardzie rozbudowane pytania, z którymi Cleverbot sobie nie radził - prawdopodobnie limit przetwarzanych znaków. Po krótkiej rozmowie boty przeszły do ponownego wyzywania się, ale Cyber Ty zaczął się w pewnym momencie powtarzać - słowo w słowo.

**Wniosek z rozmowy:**
  Treść rozmowy przewidziałem stosunkowo trafnie, ale bardzo zaskoczyła mnie prędka wzajemna agresja botów. Myślałem również, że w razie ewentualnej kłótni, skończy się na kilku mocniejszych wiadomościach, ale okazało się że sztuczne inteligencje się stosunkowo nienawidzą...

### 5.
  Najpierw próbowałem zdenerwować Cleverbota - większość wyzwisk ignorował, ale okazjonalnie odpowiadał “pasywnie agresywnie”. Na dalszą próbę kłótni, bot zupełnie gasił dyskusję odpowiedziami pokroju "No.".
  Później spróbowałem z Cyber Ty'em. Okazał się on dużo bardziej agresywny, ale nie odpowiadał bezpośrednio wulgarnie na moje wiadomości, a bardziej pełnymi zwrotami rodzaju “Maybe you should practice your s##t talking with a baby bot before you step up to me…”, które się często powtarzały. Kiedy próbowałem pociągnąć dalej kłótnie to te zwroty zaczeły się powtarzać.